Red Torque RT-X7 is a fully autonomous, self-driven robot designed for the WRO Future Engineers 2025 challenge. The system is engineered to perceive and interact intelligently with its environment using a lightweight AI-based vision module and real-time decision-making.

At the core of the robot is a camera-based object classification system powered by a TensorFlow Lite model trained with Teachable Machine. The model enables the robot to distinguish between red and green cubes â€” symbolic elements of environmental cues or objectives in the WRO challenge field. By identifying and responding to these visual markers, the robot adjusts its path, behavior, or task sequence accordingly.

The control system integrates computer vision (OpenCV), machine learning (TensorFlow Lite), and embedded motor control to allow fully autonomous operation without external input. The robot is capable of navigating its environment, identifying critical targets, and executing context-sensitive maneuvers based on visual input alone.

This project demonstrates how AI-driven perception can be embedded into compact robotic platforms, empowering them to perform smart navigation and interaction in uncertain or dynamic environments. The repository includes the complete software stack, trained models, and documentation used in development and testing.
